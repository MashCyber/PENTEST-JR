## LOG DUMPS TO S3
## USAGE
-----------------------------------------------------------------
>> The scripts iterates over a directory and uploads all files ending in ".log" after which clears the files.
>> Use below steps to upload log files to an s3 bucket and clear storage

## PRE-REQUISITES
-------------------------------------------------------------------
>> Ensure the user has adequate user rights to the specified S3 bucket

## STEP 1: INSTALL AWS CLI
-------------------------------------------------------------------
$ cd /opt
$ curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
$ unzip awscliv2.zip
$ sudo ./aws/install

## STEP 2: CONFIGURE USER PROFILE
-------------------------------------------------------------------
>> Create IAM USER with access to log s3 bucket and save Access Key & Secret Access Key. [Done]

>> Configure IAM User profile
>> (use sudo prefarably to be able to access privileged logs) <<

$ sudo aws configure --profile <<backupuser>>

AWS Access Key ID [****************]: << ACCESS KEY>>
AWS Secret Access Key [****************]: << SECRET ACCESS KEY >>
Default region name []: eu-west-1 
Default output format []: json

## STEP 3: USE BELOW SCRIPT(backup_v2.sh) TO PUSH LOGS TO S3 ==> 
## chmod +x backup_v2.sh
--------------------------------------------------------------------
#!/bin/bash

if [[ $1 ]]
then
for filename in $1*.log;
        do
        aws s3 cp \
        $filename s3://<<bucket-name>>/<<aws|ntnx>>/logs/$(date -I)/$(curl ifconfig.me)/$(basename $filename) \
        --profile <<backupuser>> \
        >> status.log 
	echo "" > $filename ;done
else
        echo "**** INCLUDE LOG PATH LOCATION ****"
        echo "###################################"
        echo " ./backup_v2.sh /path/location/log/"
        echo "###################################"
fi

### prefix location of logs either AWS | NTNX
>> <<bucket_name>> - name of bucket
>> <<aws | ntnx>>  - server host location
>> <<backupuser>>  - IAM User set for profile

NOTE: Retain dir structure as "s3://<<bucket-name>>/<<AWS|NTNX>>/logs/$(date -I)" anything afterwards is based on project for easier indexing.
e.g) s3://mybucket/ntnx/logs/$(date -I)/projectname/$(curl ifconfig.me)/...

 ## STEP 4: RUN SCRIPT (manually OR cronjob)
--------------------------------------------------------------------
./backup.sh /path/to/logs/

NOTE: Limit the individual logs file uploaded to <= 2GB , subject to network Bandwidth
